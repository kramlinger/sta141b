{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "559f7b43",
   "metadata": {},
   "source": [
    "### Discussion Week 6\n",
    "\n",
    "We will review an example that highlights the need of being proficient in xpath syntax, because we are not able to inspect the html using devtools. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d1025c",
   "metadata": {},
   "source": [
    "```markdown\n",
    "\n",
    "---\n",
    "\n",
    "## 1. What is HTML?\n",
    "\n",
    "**HTML** (HyperText Markup Language) is the standard language for creating web pages. A web page is structured by **tags** that tell a browser (or parser like BeautifulSoup) the **roles** of each piece of content: headings, paragraphs, images, links, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Basic Structure of an HTML Document\n",
    "\n",
    "A typical HTML file might look like:\n",
    "\n",
    "\\```html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "  <title>My Web Page</title>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "  <h1>Welcome to My Page</h1>\n",
    "  <p>This is a paragraph of text.</p>\n",
    "  <a href=\"https://example.com\">A Link</a>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\\```\n",
    "\n",
    "In a nutshell:\n",
    "\n",
    "- **`<html>`** is the root element; everything is inside it.  \n",
    "- **`<head>`** contains metadata (e.g., `<title>`).  \n",
    "- **`<body>`** contains the main content.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. The Parts of an HTML Tag\n",
    "\n",
    "HTML elements (often referred to as “tags”) generally have an **opening tag** and a **closing tag**:\n",
    "\n",
    "\\```html\n",
    "<p>This is a paragraph</p>\n",
    "\\```\n",
    "\n",
    "- The **opening tag** is `p` (paragraph).  \n",
    "- The **closing tag** is `/p`.  \n",
    "- The text “This is a paragraph” is the **content** of the `<p>` element.\n",
    "\n",
    "Some tags are self-closing (like `<img />` or `<br />`) and don't need a separate closing tag.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Common Tags You’ll See in Scraping\n",
    "\n",
    "1. **`<div>`**: A block-level “division” or container for grouping elements.  \n",
    "2. **`<p>`**: A paragraph of text.  \n",
    "3. **`<a>`**: An anchor (link). Often has an `href` attribute pointing to the URL.  \n",
    "4. **`<span>`**: An inline container for text.  \n",
    "5. **`<ul>`** & **`<li>`**: Unordered list (`<ul>`) and list items (`<li>`).  \n",
    "6. **`<img>`**: An image tag. Often has a `src` attribute (image URL) and can have a `title` or `alt` attribute.  \n",
    "7. **`<h1>`, `<h2>`, ...**: Headings.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Attributes: `class` and `id` (and more)\n",
    "\n",
    "**Attributes** are key–value pairs in the tag’s opening bracket that provide extra information. For example:\n",
    "\n",
    "\\```html\n",
    "<p class=\"intro\" id=\"first-paragraph\">Hello World!</p>\n",
    "\\```\n",
    "\n",
    "- **class=\"intro\"**: The `class` attribute is often used for styling (CSS) or identifying groups of elements.  \n",
    "- **id=\"first-paragraph\"**: The `id` attribute should be unique on the page. Often used for JavaScript targeting or to link to a specific section.  \n",
    "\n",
    "When scraping, we commonly use:\n",
    "\n",
    "- **`class_=\"some-class\"`** in `BeautifulSoup` (note the underscore to avoid Python’s reserved word `class`)  \n",
    "- **`id=\"some-id\"`** in `BeautifulSoup`\n",
    "\n",
    "We also encounter other attributes, like:\n",
    "\n",
    "- **`href`** in `<a>` tags (the URL link).  \n",
    "- **`src`** in `<img>` tags (the image source).  \n",
    "- **`title`** or **`alt`** on various tags (extra descriptive text).\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Nesting of Tags\n",
    "\n",
    "HTML tags can be **nested**. For instance:\n",
    "\n",
    "\\```html\n",
    "<div id=\"main-container\">\n",
    "  <h2>Section Title</h2>\n",
    "  <p class=\"description\">\n",
    "    Here is some text with an <a href=\"https://example.com\">example link</a>.\n",
    "  </p>\n",
    "</div>\n",
    "\\```\n",
    "\n",
    "When you use `soup.prettify()`, you’ll see these tags indented to show that `<h2>` and `<p>` are inside the `<div>`, and that `<a>` is inside the `<p>`.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. How This Relates to BeautifulSoup\n",
    "\n",
    "When you run:\n",
    "\n",
    "\\```python\n",
    "print(soup.prettify())\n",
    "\\```\n",
    "\n",
    "You’ll see:\n",
    "\n",
    "1. **Opening and closing tags**: like `<div> ... </div>`.  \n",
    "2. **Attributes**: `<p class=\"description\">`, `<a href=\"...\">`.  \n",
    "3. **Nested structure**: Indentation shows which tags are inside others.\n",
    "\n",
    "### Common BeautifulSoup Methods/Concepts\n",
    "\n",
    "1. **`find()`**: Returns the **first** matching element. Example:\n",
    "\n",
    "   \\```python\n",
    "   container = soup.find('div', id='main-container')\n",
    "   \\```\n",
    "\n",
    "   - Looks for a `<div>` with `id=\"main-container\"`.\n",
    "\n",
    "2. **`find_all()`**: Returns **all** matching elements as a list.\n",
    "\n",
    "   \\```python\n",
    "   paragraphs = soup.find_all('p', class_='description')\n",
    "   \\```\n",
    "\n",
    "   - Looks for **all** `<p>` tags whose `class` is `\"description\"`.\n",
    "\n",
    "3. **CSS Selectors (`.select()`)**:\n",
    "\n",
    "   \\```python\n",
    "   # \"p.description\" means: find <p> with class=\"description\"\n",
    "   paragraphs = soup.select(\"p.description\")\n",
    "   \\```\n",
    "\n",
    "   - This is like using CSS rules to find elements.\n",
    "\n",
    "4. **Tag Text**:\n",
    "\n",
    "   \\```python\n",
    "   my_paragraph = soup.find('p', class_='description')\n",
    "   print(my_paragraph.get_text(strip=True))\n",
    "   \\```\n",
    "\n",
    "   - `get_text(strip=True)` extracts the text content, removing extra spaces.\n",
    "\n",
    "5. **Tag Attributes**:\n",
    "\n",
    "   \\```python\n",
    "   link = soup.find('a')\n",
    "   url = link['href']  # or link.get('href')\n",
    "   \\```\n",
    "\n",
    "   - Accessing the `href` attribute of an `<a>` tag.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Tips for Reading HTML with `prettify()`\n",
    "\n",
    "When you see something like:\n",
    "\n",
    "\\```html\n",
    "<div id=\"seven-day-forecast-container\">\n",
    "  <ul class=\"list-unstyled\" id=\"seven-day-forecast-list\">\n",
    "    <li class=\"forecast-tombstone\">\n",
    "      <div class=\"tombstone-container\">\n",
    "        <p class=\"period-name\">Monday</p>\n",
    "        <p class=\"short-desc\">Sunny</p>\n",
    "        <p class=\"temp temp-high\">High: 75 °F</p>\n",
    "      </div>\n",
    "    </li>\n",
    "    ...\n",
    "  </ul>\n",
    "</div>\n",
    "\\```\n",
    "\n",
    "you can read it as:\n",
    "\n",
    "- A **`<div>`** with `id=\"seven-day-forecast-container\"`.  \n",
    "- Inside it, a **`<ul>`** with `id=\"seven-day-forecast-list\"`.  \n",
    "- Then each **`<li>`** (list item) has a `<div>` for the “tombstone” (forecast box).  \n",
    "- That `<div>` contains three **`<p>`** elements for period name, short description, and temperature.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Summary\n",
    "\n",
    "1. **HTML = tags + attributes + nested structure.**  \n",
    "2. **`class`** and **`id`** attributes are your best friends for scraping—they help locate specific elements.  \n",
    "3. **Use** BeautifulSoup’s methods like:\n",
    "   - `.find()`, `.find_all()`, or `.select()` to locate tags by name, class, or id.  \n",
    "   - `.get_text()` to extract text content.  \n",
    "   - `.get(<attribute_name>)` to grab specific attribute values (like `href`, `title`, etc.).\n",
    "\n",
    "Once you can **recognize** these tags, **navigate** their nesting, and **understand** how to target them by `class`, `id`, or tag name, you have the **foundation** you need to read `prettify()` output and scrape effectively with BeautifulSoup.\n",
    "\n",
    "---\n",
    "\n",
    "**That’s it!** Now you have a brief introduction to the parts of HTML that matter most for scraping. You don’t need to memorize all HTML tags or advanced layouts—just focus on **seeing** which tags hold the data you want and how you can target them with BeautifulSoup.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3441d5f1",
   "metadata": {},
   "source": [
    "## Xpath Scraping Examples & Explanation\n",
    "\n",
    "\n",
    "```markdown\n",
    "# Discussion: XPath Fundamentals and Practical Scraping\n",
    "\n",
    "XPath (XML Path Language) is a query language for selecting nodes from an XML/HTML document. With XPath, we can precisely locate elements in a structured document based on tags, attributes, text, and hierarchy.\n",
    "\n",
    "In web scraping scenarios, especially when working with HTML documents, XPath offers powerful capabilities such as:\n",
    "- **Selecting elements by tag** (e.g., `//a`, `//table`, etc.)\n",
    "- **Selecting elements by attribute** (e.g., `//div[@class=\"content\"]`)\n",
    "- **Selecting elements containing specific text** (e.g., `//td[contains(text(), \"Genre\")]`)\n",
    "- **Navigating the tree structure** (using child, sibling, or ancestor axes, such as `parent::`, `following-sibling::`, `preceding-sibling::`, etc.)\n",
    "\n",
    "Often, the HTML you get via an HTTP library (e.g., `requests`) can differ from what you see in your browser, because many sites serve different HTML to mobile vs. desktop clients, or because scripts dynamically manipulate the DOM. This can make scraping challenging if you rely solely on DevTools to copy selectors from a rendered page. Below is an illustrative example using `requests` and `lxml` to scrape [imsdb.com](https://imsdb.com/).\n",
    "\n",
    "---\n",
    "\n",
    "## Scraping Genre Links Example\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import lxml.html as lx\n",
    "\n",
    "# Step 1: Retrieve the page's HTML\n",
    "result = requests.get('https://imsdb.com/')\n",
    "result.raise_for_status()  # Ensure no HTTP errors\n",
    "html_content = result.text\n",
    "\n",
    "# Step 2: Parse the HTML content\n",
    "html = lx.fromstring(html_content)\n",
    "\n",
    "# Step 3: (Demonstration) Trying to select a specific <table><tbody> might return empty\n",
    "# (because the structure is different from what we see in some device view)\n",
    "genre_table = html.xpath('//table/tbody')\n",
    "print(\"Attempt to find table/tbody:\", genre_table)  # Likely returns []\n",
    "\n",
    "# Step 4: Different HTML is served depending on viewport/device. In some views,\n",
    "# the 'Genres' section might appear as a table row with a specific <td> containing the text \"Genre\".\n",
    "# In other (mobile) views, it might not appear at all (or only as a script-generated dropdown).\n",
    "# Let's assume we have the \"desktop\" or large-viewport HTML.\n",
    "\n",
    "# One trick: look for the table row containing the cell with text \"Genre\" \n",
    "# (or partial match in case there's trailing whitespace like \"\\r\\n\").\n",
    "genres = html.xpath('//table[tr/td[contains(text(), \"Genre\")]]/tr//a/@href')\n",
    "print(\"Genre links found:\", genres)\n",
    "\n",
    "# Explanation:\n",
    "#  - //table[tr/td[contains(text(), \"Genre\")]]: find a <table> that has a <tr>-><td> containing \"Genre\"\n",
    "#  - /tr//a/@href: within that table, find all <a> elements inside <tr> and return their \"href\" attributes\n",
    "```\n",
    "\n",
    "In many real-world scenarios, you must carefully inspect the raw HTML returned by `requests` (rather than the rendered HTML in your browser) to craft XPath queries that match the actual structure you’re scraping.\n",
    "\n",
    "---\n",
    "\n",
    "## Scraping Script Date Example\n",
    "\n",
    "In another scenario, suppose we want to retrieve the movie release year from a page like:\n",
    "[Interstellar Script](https://imsdb.com/Movie%20Scripts/Interstellar%20Script.html).\n",
    "\n",
    "After inspecting the HTML (mindful it may differ between desktop and mobile), we note that the script date is found as text after a `<b>` element with the text `\"Script Date\"`. For example:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import lxml.html as lx\n",
    "\n",
    "url = 'https://imsdb.com/Movie%20Scripts/Interstellar%20Script.html'\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "html = lx.fromstring(response.text)\n",
    "\n",
    "# We'll extract all text from <td> elements within the table that has class=\"script-details\"\n",
    "script_details_texts = html.xpath('//table[@class=\"script-details\"]//td/text()')\n",
    "print(\"Script details (all text):\", script_details_texts)\n",
    "\n",
    "# If we specifically want the text node immediately following the <b> element that has text \"Script Date\":\n",
    "date_text = html.xpath('//b[text()=\"Script Date\"]/following-sibling::text()[1]')\n",
    "print(\"Raw script date text:\", date_text)\n",
    "\n",
    "# The returned text might contain additional words, whitespace, or punctuation.\n",
    "# Next, we'd typically use regular expressions to isolate the four-digit year from the text.\n",
    "# For now, we'll just demonstrate that the immediate text is captured.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways on XPath Usage\n",
    "\n",
    "1. **Absolute vs. Relative Paths**  \n",
    "   - `//tag` searches for `<tag>` anywhere in the document, while `/tag` searches only in the immediate children of the current node.\n",
    "\n",
    "2. **Attribute Conditions**  \n",
    "   - `//div[@class=\"nav\"]` selects `<div>` elements with `class=\"nav\"`.\n",
    "\n",
    "3. **Text Matching**  \n",
    "   - `//td[text()=\"Genre\"]` matches a `<td>` whose **entire** text content is `\"Genre\"`.\n",
    "   - `//td[contains(text(),\"Genre\")]` matches a `<td>` whose text content contains `\"Genre\"` as a substring.\n",
    "\n",
    "4. **Handling Whitespace & Newlines**  \n",
    "   - Real HTML often includes line breaks like `\\r\\n`. To handle partial matches, use `contains()` or normalize space if needed.\n",
    "\n",
    "5. **Navigation Axes**  \n",
    "   - `following-sibling::`, `preceding-sibling::`, `parent::`, `child::`, etc. let you move in the document relative to a known node.\n",
    "\n",
    "By understanding these XPath strategies, you can more flexibly navigate HTML structures that aren’t always consistent — especially when the site provides different renders (e.g., mobile vs. desktop) or dynamically alters the DOM via JavaScript.\n",
    "\n",
    "---\n",
    "\n",
    "**Note:**  \n",
    "To handle tricky situations where the page is significantly different when rendered in a browser (due to JavaScript or device-based rendering), you may need to:\n",
    "- Emulate a specific User-Agent and send the correct headers to get the “desktop” version.\n",
    "- Use a headless browser solution (e.g., `Selenium`, `Playwright`) to execute JavaScript and get the fully rendered page.\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a8370",
   "metadata": {},
   "source": [
    "## Extended XPath Overview & Examples\n",
    "\n",
    "\n",
    "```markdown\n",
    "# Key Takeaways on XPath Usage\n",
    "\n",
    "## Absolute vs. Relative Paths\n",
    "- `//tag` searches for `<tag>` anywhere in the document.\n",
    "- `/tag` searches for `<tag>` only in the immediate children of the current node (i.e., from the root in a full path).\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "# Absolute path from the document root\n",
    "html.xpath('/html/body/div/p')\n",
    "\n",
    "# Relative path (searches anywhere in the document)\n",
    "html.xpath('//p')\n",
    "```\n",
    "\n",
    "## Attribute Conditions\n",
    "- `//div[@class=\"nav\"]` selects all `<div>` elements with `class=\"nav\"`.\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "# Select all <img> elements whose \"alt\" attribute equals \"logo\"\n",
    "html.xpath('//img[@alt=\"logo\"]')\n",
    "```\n",
    "\n",
    "## Text Matching\n",
    "- `//td[text()=\"Genre\"]` matches a `<td>` whose entire text content is `\"Genre\"`.\n",
    "- `//td[contains(text(),\"Genre\")]` matches a `<td>` whose text content contains `\"Genre\"` as a substring.\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "# Exact text match\n",
    "html.xpath('//span[text()=\"Subscribe\"]')\n",
    "\n",
    "# Partial text match (avoids issues with whitespace or additional text)\n",
    "html.xpath('//span[contains(text(), \"Subscribe\")]')\n",
    "```\n",
    "\n",
    "## Handling Whitespace & Newlines\n",
    "HTML often includes line breaks like `\\r\\n`. To handle partial matches, you can use:\n",
    "- `contains()`\n",
    "- Functions like `normalize-space()`\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "# Using contains() to avoid missing text with stray newline characters\n",
    "html.xpath('//td[contains(text(), \"Genre\")]')\n",
    "\n",
    "# Using normalize-space() if there's excessive spacing\n",
    "html.xpath('//td[normalize-space(text())=\"Genre\"]')\n",
    "```\n",
    "\n",
    "## Navigation Axes\n",
    "- `following-sibling::`, `preceding-sibling::`, `parent::`, `child::`, etc.  \n",
    "  These allow you to move in the document relative to a known node.\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "# Select the text node following a <b> element with text 'Script Date'\n",
    "html.xpath('//b[text()=\"Script Date\"]/following-sibling::text()[1]')\n",
    "\n",
    "# Select any <div> that is the parent of an <img> with src=\"logo.png\"\n",
    "html.xpath('//img[@src=\"logo.png\"]/parent::div')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# Additional XPath Grammar and Methods\n",
    "\n",
    "Below we introduce more XPath concepts, including wildcard usage, union operators, and common functions for more powerful queries.\n",
    "\n",
    "## Wildcards\n",
    "- `*` matches any element node (regardless of its name).\n",
    "- `@*` matches any attribute node.\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "# Select all child elements under <div> of class \"container\", regardless of tag name\n",
    "html.xpath('//div[@class=\"container\"]/*')\n",
    "\n",
    "# Select all attributes of the <img> elements\n",
    "html.xpath('//img/@*')\n",
    "```\n",
    "\n",
    "## Union (|) Operator\n",
    "- Combines multiple XPath expressions so you can select multiple sets of nodes.\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "# Select all <div> or <span> elements\n",
    "html.xpath('//div | //span')\n",
    "```\n",
    "\n",
    "## Common Functions\n",
    "- `starts-with(string, substring)`: Tests if `string` starts with `substring`.\n",
    "- `substring(string, start, length)`: Returns a portion of `string`.\n",
    "- `string-length(string)`: Returns the length of a string.\n",
    "- `count(node-set)`: Returns the number of nodes in a node set.\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "# Select <a> elements whose href starts with \"https\"\n",
    "html.xpath('//a[starts-with(@href, \"https\")]')\n",
    "\n",
    "# Count how many <p> elements exist\n",
    "num_paragraphs = html.xpath('count(//p)')\n",
    "print(\"Number of <p> elements:\", num_paragraphs)\n",
    "```\n",
    "\n",
    "## Context Nodes and Parent/Child Notation\n",
    "- `.` refers to the current context node.\n",
    "- `..` refers to the parent of the current node.\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "# From a known element \"el\", select its parent's sibling divs\n",
    "el.xpath('../following-sibling::div')\n",
    "```\n",
    "\n",
    "## Putting It All Together\n",
    "When crafting your XPath, you often combine these features:\n",
    "1. Start with a known node or wildcard.\n",
    "2. Use predicate filters on attributes/text/position.\n",
    "3. Employ axes to move to siblings, parents, children, etc.\n",
    "4. Apply string functions or partial matches to handle real-world HTML quirks.\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "# 1. Find a table containing a <td> with text \"Genre\"\n",
    "# 2. Then locate all <a> within that table (in any row).\n",
    "genre_links = html.xpath('//table[tr/td[contains(text(), \"Genre\")]]//a/@href')\n",
    "\n",
    "# 3. Move from a known <b> element's text to the next text node.\n",
    "release_date_text = html.xpath('//b[text()=\"Script Date\"]/following-sibling::text()[1]')\n",
    "\n",
    "# 4. Use starts-with() to filter anchor links that begin with \"/scripts\".\n",
    "script_links = html.xpath('//a[starts-with(@href, \"/scripts\")]/@href')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "By understanding these XPath strategies and methods, you can become more agile in navigating and extracting data from HTML documents that vary in layout or contain dynamic elements. Always remember to inspect the **actual** HTML returned by your HTTP client (e.g., `requests`) rather than relying solely on the rendered DOM in a browser, which may include additional transformations or scripts.\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1ee2ac",
   "metadata": {},
   "source": [
    "# Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff3f282",
   "metadata": {},
   "source": [
    "## Tutorial: Beautiful Soup Basics\n",
    "\n",
    "\n",
    "```markdown\n",
    "# Tutorial: Beautiful Soup Basics\n",
    "\n",
    "Beautiful Soup is a Python library designed for quick turnaround projects like screen-scraping. Here's a brief step-by-step tutorial that outlines how to get started:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Installation\n",
    "\n",
    "Before using Beautiful Soup, you need to install it. If you haven’t already:\n",
    "\n",
    "```bash\n",
    "pip install beautifulsoup4\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Importing and Creating a Soup Object\n",
    "\n",
    "To begin parsing HTML, import both `requests` (or another HTTP library) and `BeautifulSoup`:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Fetch a webpage\n",
    "url = \"https://example.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML text\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Alternatively, parse an HTML string directly\n",
    "html_doc = \"<html><body><p>Hello!</p></body></html>\"\n",
    "soup_from_string = BeautifulSoup(html_doc, \"html.parser\")\n",
    "```\n",
    "\n",
    "A `BeautifulSoup` object (`soup` in these examples) acts as a structured representation of your HTML. You can navigate and search it like a tree.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Parsing and Navigating the HTML Tree\n",
    "\n",
    "### 3.1 Accessing Elements by Tag\n",
    "\n",
    "```python\n",
    "# Access the first <title> tag found in the document\n",
    "page_title = soup.title\n",
    "\n",
    "# Access the first <body> tag\n",
    "page_body = soup.body\n",
    "\n",
    "# Access the first <p> tag\n",
    "paragraph = soup.p\n",
    "```\n",
    "\n",
    "Remember that these direct accesses (`soup.p`, `soup.title`) only give you **the first** occurrence of that tag.\n",
    "\n",
    "### 3.2 Going Down the Tree\n",
    "\n",
    "- `.contents` gives a list of **all children** of a tag.\n",
    "- `.children` is an **iterator** over those children.\n",
    "\n",
    "```python\n",
    "# If we want to see what's inside <body>\n",
    "print(soup.body.contents)\n",
    "\n",
    "# Or iterate over the children:\n",
    "for child in soup.body.children:\n",
    "    print(child)\n",
    "```\n",
    "\n",
    "### 3.3 Going Up the Tree\n",
    "\n",
    "If you have a tag, you can find its parent:\n",
    "\n",
    "```python\n",
    "# Access a tag's parent\n",
    "if soup.p:\n",
    "    parent_of_p = soup.p.parent\n",
    "    print(\"Parent of <p>:\", parent_of_p.name)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Finding Elements\n",
    "\n",
    "### 4.1 `find_all()`\n",
    "\n",
    "`find_all()` returns **all** matches of your query:\n",
    "\n",
    "```python\n",
    "# All paragraph tags\n",
    "paragraphs = soup.find_all(\"p\")\n",
    "\n",
    "# All tags that have class=\"important\"\n",
    "important_tags = soup.find_all(class_=\"important\")\n",
    "```\n",
    "\n",
    "### 4.2 `find()`\n",
    "\n",
    "`find()` returns **the first** match:\n",
    "\n",
    "```python\n",
    "# First <p> tag with class \"important\"\n",
    "first_important_p = soup.find(\"p\", class_=\"important\")\n",
    "```\n",
    "\n",
    "### 4.3 CSS Selectors via `.select()`\n",
    "\n",
    "Use `.select()` to match elements using CSS selectors (like in a browser’s DevTools):\n",
    "\n",
    "```python\n",
    "# All <p> tags\n",
    "paragraphs_css = soup.select(\"p\")\n",
    "\n",
    "# A <p> tag with id=\"best-paragraph\"\n",
    "best_paragraph = soup.select(\"p#best-paragraph\")\n",
    "\n",
    "# A <p> tag with class=\"important\"\n",
    "important_paragraphs = soup.select(\"p.important\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Extracting Text and Attributes\n",
    "\n",
    "### 5.1 `.get_text()`\n",
    "\n",
    "`get_text()` returns **all** text within a tag (including its descendants), stripped of HTML tags:\n",
    "\n",
    "```python\n",
    "body_text = soup.body.get_text()\n",
    "print(body_text)\n",
    "```\n",
    "\n",
    "### 5.2 Accessing Attributes\n",
    "\n",
    "Tags can be treated like a dictionary to get/set attributes:\n",
    "\n",
    "```python\n",
    "some_link = soup.find(\"a\")\n",
    "if some_link:\n",
    "    href_value = some_link[\"href\"]   # Might raise KeyError if \"href\" missing\n",
    "    safer_href = some_link.get(\"href\", \"No link available\")\n",
    "    print(\"Link:\", safer_href)\n",
    "```\n",
    "\n",
    "You can also view the entire attributes dictionary:\n",
    "\n",
    "```python\n",
    "print(some_link.attrs)  # e.g., {\"href\": \"https://example.com\"}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Advanced Tasks\n",
    "\n",
    "Below are some advanced tasks you can perform with Beautiful Soup:\n",
    "\n",
    "1. **Filtering by Function**  \n",
    "   You can pass a function to `find_all()` or `find()` to define a custom matching condition.\n",
    "\n",
    "2. **Modifying the Parse Tree**  \n",
    "   You can insert, delete, or reorder tags within the parsed structure.\n",
    "\n",
    "3. **Handling Non-Standard Documents**  \n",
    "   Beautiful Soup is forgiving of poorly formed HTML, but you might need to experiment with different parsers (e.g., `\"html5lib\"`).\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Output and Debugging\n",
    "\n",
    "### 7.1 `.prettify()`\n",
    "\n",
    "```python\n",
    "print(soup.prettify())      # Prints the entire HTML in a nicely formatted way\n",
    "print(soup.body.prettify()) # Prints just the <body> section\n",
    "```\n",
    "\n",
    "This helps you understand the structure that Beautiful Soup sees, which may differ from the raw HTML if there are minor errors.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a30837",
   "metadata": {},
   "source": [
    "# Example 2: National Weather Service\n",
    "\n",
    "Let's scrape the [National Weather Service](https://weather.gov/) for the weather forecast of Davis, CA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389b4cfe",
   "metadata": {},
   "source": [
    "## Annotated Example: Scraping the National Weather Service\n",
    "\n",
    "\n",
    "```markdown\n",
    "# Scraping the National Weather Service: Davis, CA Forecast\n",
    "\n",
    "In this example, we’ll demonstrate how to:\n",
    "1. Send an HTTP request to the National Weather Service page for Davis, CA.\n",
    "2. Parse the HTML response with Beautiful Soup.\n",
    "3. Extract specific weather data (period names, short descriptions, temperatures, and detailed descriptions).\n",
    "4. Assemble the data into a pandas DataFrame.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a8e45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Period              Description  Temperature  \\\n",
      "0  NOW until 10:00am Fri            Flood Warning   Low: 46 °F   \n",
      "1                Tonight                  Showers  High: 60 °F   \n",
      "2               Thursday                  Showers   Low: 48 °F   \n",
      "3         Thursday Night  Showers thenRain Likely  High: 61 °F   \n",
      "4                 Friday              Chance Rain   Low: 40 °F   \n",
      "5           Friday Night             Mostly Clear  High: 59 °F   \n",
      "6               Saturday             Partly Sunny   Low: 42 °F   \n",
      "7         Saturday Night            Mostly Cloudy  High: 59 °F   \n",
      "\n",
      "                                              Detail  \n",
      "0                                                     \n",
      "1                                                     \n",
      "2  Rain, mainly before 4pm, then showers and poss...  \n",
      "3  Showers and possibly a thunderstorm before 10p...  \n",
      "4  A 40 percent chance of rain, mainly before 10a...  \n",
      "5  Mostly clear, with a low around 40. South sout...  \n",
      "6                 Partly sunny, with a high near 59.  \n",
      "7               Mostly cloudy, with a low around 42.  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 1: Identify the Target URL\n",
    "# ----------------------------------------------------------------------------\n",
    "# This URL corresponds to the National Weather Service’s 7-day forecast\n",
    "# for a specific latitude/longitude near Davis, CA.\n",
    "url = \"https://forecast.weather.gov/MapClick.php?lat=38.54669&lon=-121.74457#.Y9fY5vv565t\"\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 2: Fetch the Page Content\n",
    "# ----------------------------------------------------------------------------\n",
    "try:\n",
    "    # 'requests.get(url)' sends an HTTP GET request to the specified URL.\n",
    "    # The server's response is stored in the 'response' variable.\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # 'raise_for_status()' will raise a 'requests.exceptions.HTTPError' if\n",
    "    # the server returned an unsuccessful status code (e.g., 404, 500).\n",
    "    response.raise_for_status()\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    # If *any* Request-related error occurs (connection error, timeout, etc.),\n",
    "    # print the error and exit the script gracefully.\n",
    "    print(f\"Error fetching {url}:\\n{e}\")\n",
    "    raise SystemExit\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3: Parse HTML with BeautifulSoup\n",
    "# ----------------------------------------------------------------------------\n",
    "# 'response.text' gives us the HTML content of the response.\n",
    "# BeautifulSoup constructs a \"soup\" object from that text for easy parsing.\n",
    "html_soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 4: Identify and Validate the \"Seven-Day Forecast\" Section\n",
    "# ----------------------------------------------------------------------------\n",
    "# The page structure (from NWS) typically includes a <div> with id=\"seven-day-forecast-container\".\n",
    "# We find it using 'html_soup.find(id=\"...\")'.\n",
    "seven_day = html_soup.find(id=\"seven-day-forecast-container\")\n",
    "\n",
    "# If 'find' returned None, it means it couldn’t locate that <div> — likely\n",
    "# because the site’s structure changed or the page didn’t load fully.\n",
    "if not seven_day:\n",
    "    raise ValueError(\n",
    "        \"Could not find the element with id='seven-day-forecast-container'. \"\n",
    "        \"The site structure may have changed.\"\n",
    "    )\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Optional: Debugging / Inspect the snippet\n",
    "# ----------------------------------------------------------------------------\n",
    "# If you want to see exactly what we got in 'seven_day', you can uncomment the line:\n",
    "# print(seven_day.prettify())\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 5: Extract the Forecast Period Names\n",
    "# ----------------------------------------------------------------------------\n",
    "# .find_all(\"p\", class_=\"period-name\") means:\n",
    "# - Look inside the 'seven_day' object\n",
    "# - Find ALL <p> tags whose 'class' attribute is \"period-name\".\n",
    "# Because there might be multiple 'period-name' paragraphs (e.g., \"Tonight\", \"Wednesday\", etc.),\n",
    "# .find_all() returns a list of matching <p> elements.\n",
    "period_names = seven_day.find_all(\"p\", class_=\"period-name\")\n",
    "\n",
    "# We then iterate over each found <p> element and use .get_text(strip=True)\n",
    "# to extract only the text content, trimming whitespace.\n",
    "period = [name.get_text(strip=True) for name in period_names]\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 6: Extract the Short Weather Descriptions\n",
    "# ----------------------------------------------------------------------------\n",
    "# Similarly, we look for <p> elements whose class is \"short-desc\",\n",
    "# which typically shows a phrase like \"Rain\", \"Mostly Sunny\", \"Snow Likely\", etc.\n",
    "descs = seven_day.find_all(\"p\", class_=\"short-desc\")\n",
    "\n",
    "# Again, we strip each match’s text content.\n",
    "description = [desc.get_text(strip=True) for desc in descs]\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 7: Extract the Temperatures\n",
    "# ----------------------------------------------------------------------------\n",
    "# Temperatures often appear in <p> tags whose class includes \"temp\",\n",
    "# e.g. class=\"temp temp-high\" or class=\"temp temp-low\".\n",
    "# We use a CSS selector \"p[class*='temp']\" to match any <p> whose class\n",
    "# attribute CONTAINS the substring \"temp\".\n",
    "temps = seven_day.select(\"p[class*='temp']\")\n",
    "\n",
    "# Then we extract and strip the text from each of these <p> tags.\n",
    "temperature = [temp.get_text(strip=True) for temp in temps]\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 8: Extract Detailed Descriptions from <img> Tags\n",
    "# ----------------------------------------------------------------------------\n",
    "# Each forecast \"tombstone\" has an <img> whose 'title' attribute provides\n",
    "# a more detailed description, often including chance of precipitation, wind info, etc.\n",
    "images = seven_day.select(\"div.tombstone-container img\")\n",
    "\n",
    "# We'll collect the 'title' attribute from each <img>. Some images might not have one,\n",
    "# so we use .get(\"title\", \"\") instead of ['title'] to avoid KeyErrors.\n",
    "details = []\n",
    "for image in images:\n",
    "    title_text = image.get(\"title\", \"\")\n",
    "    details.append(title_text)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 9: Clean Up the Detailed Descriptions\n",
    "# ----------------------------------------------------------------------------\n",
    "# Many of these 'title' strings begin with the period name, followed by a colon.\n",
    "# E.g. \"Thursday: Rain, mainly after 4pm. High near 60...\"\n",
    "# We want just the forecast text after the colon.\n",
    "def clean_detail(txt):\n",
    "    # If there's no colon, just return the entire text trimmed.\n",
    "    if \":\" not in txt:\n",
    "        return txt.strip()\n",
    "    # If there is a colon, split into three parts with .partition(\":\")\n",
    "    # and return index 2 (the substring after the colon).\n",
    "    return txt.partition(\":\")[2].strip()\n",
    "\n",
    "# Apply our cleanup function to every string in 'details'.\n",
    "new_details = [clean_detail(d) for d in details]\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 10: Ensure Lists Have the Same Length (Optional Check)\n",
    "# ----------------------------------------------------------------------------\n",
    "# Sometimes, the site includes extra hazard items or fewer periods,\n",
    "# causing mismatches in the list lengths. Pandas can handle mismatches but\n",
    "# it may misalign rows. Here, we find the min length and truncate each list:\n",
    "min_length = min(len(period), len(description), len(temperature), len(new_details))\n",
    "period = period[:min_length]\n",
    "description = description[:min_length]\n",
    "temperature = temperature[:min_length]\n",
    "new_details = new_details[:min_length]\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 11: Create a DataFrame\n",
    "# ----------------------------------------------------------------------------\n",
    "# We build a pandas DataFrame mapping each column name (\"Period\", \"Description\", etc.)\n",
    "# to the lists we collected.\n",
    "weather = pd.DataFrame({\n",
    "    \"Period\": period,\n",
    "    \"Description\": description,\n",
    "    \"Temperature\": temperature,\n",
    "    \"Detail\": new_details\n",
    "})\n",
    "\n",
    "# Finally, print the DataFrame to see a table of the extracted forecast data.\n",
    "print(weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8555c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div id=\"seven-day-forecast-container\">\n",
      " <div class=\"current-hazard\" id=\"headline-container\" style=\"margin-left: 124px\">\n",
      "  <div id=\"headline-separator\" style=\"top: 34px; height: 171px\">\n",
      "  </div>\n",
      "  <div id=\"headline-info\" onclick=\"$('#headline-detail').toggle(); $('#headline-detail-now').hide()\" style=\"margin-top: 5px\">\n",
      "   <div id=\"headline-detail\">\n",
      "    <div>\n",
      "     Flood Watch until February 14, 10:00pm\n",
      "    </div>\n",
      "    <div>\n",
      "     Wind Advisory until February 14, 10:00am\n",
      "    </div>\n",
      "    <div>\n",
      "     Flood Warning February 12, 10:29pm until February 14, 10:00am\n",
      "    </div>\n",
      "   </div>\n",
      "   <span class=\"fa fa-info-circle\">\n",
      "   </span>\n",
      "   Click here for hazard details and duration\n",
      "  </div>\n",
      "  <div class=\"headline-bar headline-watch\" style=\"top: 40px; left: 19px; height: 165px; width: 518px\">\n",
      "   <div class=\"headline-title\">\n",
      "    Flood Watch\n",
      "   </div>\n",
      "  </div>\n",
      "  <div class=\"headline-bar headline-advisory\" style=\"top: 60px; left: 19px; height: 145px; width: 394px\">\n",
      "   <div class=\"headline-title\">\n",
      "    Wind Advisory\n",
      "   </div>\n",
      "  </div>\n",
      "  <div class=\"headline-bar headline-warning\" style=\"top: 80px; left: 19px; height: 125px; width: 394px\">\n",
      "   <div class=\"headline-title\">\n",
      "    Flood Warning\n",
      "   </div>\n",
      "  </div>\n",
      " </div>\n",
      " <ul class=\"list-unstyled\" id=\"seven-day-forecast-list\" style=\"padding-top: 100px\">\n",
      "  <li class=\"forecast-tombstone current-hazard current-hazard-warning\" onclick=\"$('#headline-detail-now').toggle(); $('#headline-detail').hide()\">\n",
      "   <div class=\"top-bar\">\n",
      "    <div id=\"headline-detail-now\">\n",
      "     <div>\n",
      "      Flood Watch until February 14, 10:00pm\n",
      "     </div>\n",
      "     <div>\n",
      "      Wind Advisory until February 14, 10:00am\n",
      "     </div>\n",
      "     <div>\n",
      "      Flood Warning February 12, 10:29pm until February 14, 10:00am\n",
      "     </div>\n",
      "    </div>\n",
      "    <span class=\"tab\">\n",
      "    </span>\n",
      "    <span class=\"fa fa-info-circle\">\n",
      "    </span>\n",
      "   </div>\n",
      "   <div class=\"tombstone-container\">\n",
      "    <p class=\"period-name\">\n",
      "     NOW: Multiple hazards in effect\n",
      "    </p>\n",
      "    <p>\n",
      "     <img class=\"forecast-icon\" src=\"newimages/medium/nshra.png\"/>\n",
      "    </p>\n",
      "    <p class=\"short-desc\">\n",
      "     Click HERE for Details\n",
      "    </p>\n",
      "   </div>\n",
      "  </li>\n",
      "  <li class=\"forecast-tombstone\">\n",
      "   <div class=\"tombstone-container\">\n",
      "    <p class=\"period-name\">\n",
      "     Tonight\n",
      "    </p>\n",
      "    <p>\n",
      "     <img alt=\"\" class=\"forecast-icon\" src=\"newimages/medium/nshra100.png\" title=\"\"/>\n",
      "    </p>\n",
      "    <p class=\"temp temp-low\">\n",
      "     Low: 46 °F\n",
      "     <span style=\"color: #000000; font-weight:normal;\">\n",
      "      ⇑\n",
      "     </span>\n",
      "    </p>\n",
      "    <p class=\"short-desc\">\n",
      "     Showers\n",
      "    </p>\n",
      "   </div>\n",
      "  </li>\n",
      "  <li class=\"forecast-tombstone\">\n",
      "   <div class=\"tombstone-container\">\n",
      "    <p class=\"period-name\">\n",
      "     Thursday\n",
      "    </p>\n",
      "    <p>\n",
      "     <img alt=\"Thursday: Rain, mainly before 4pm, then showers and possibly a thunderstorm after 4pm.  High near 60. South southwest wind 16 to 21 mph, with gusts as high as 39 mph.  Chance of precipitation is 80%. New rainfall amounts between a half and three quarters of an inch possible. \" class=\"forecast-icon\" src=\"newimages/medium/shra80.png\" title=\"Thursday: Rain, mainly before 4pm, then showers and possibly a thunderstorm after 4pm.  High near 60. South southwest wind 16 to 21 mph, with gusts as high as 39 mph.  Chance of precipitation is 80%. New rainfall amounts between a half and three quarters of an inch possible. \"/>\n",
      "    </p>\n",
      "    <p class=\"temp temp-high\">\n",
      "     High: 60 °F\n",
      "    </p>\n",
      "    <p class=\"short-desc\">\n",
      "     Showers\n",
      "    </p>\n",
      "   </div>\n",
      "  </li>\n",
      "  <li class=\"forecast-tombstone\">\n",
      "   <div class=\"tombstone-container\">\n",
      "    <p class=\"period-name\">\n",
      "     Thursday Night\n",
      "    </p>\n",
      "    <p>\n",
      "     <img alt=\"Thursday Night: Showers and possibly a thunderstorm before 10pm, then rain likely, mainly between 10pm and 4am.  Low around 48. South wind 11 to 15 mph, with gusts as high as 30 mph.  Chance of precipitation is 100%. New precipitation amounts of less than a tenth of an inch, except higher amounts possible in thunderstorms. \" class=\"forecast-icon\" src=\"DualImage.php?i=nshra&amp;j=nshra&amp;ip=100&amp;jp=70\" title=\"Thursday Night: Showers and possibly a thunderstorm before 10pm, then rain likely, mainly between 10pm and 4am.  Low around 48. South wind 11 to 15 mph, with gusts as high as 30 mph.  Chance of precipitation is 100%. New precipitation amounts of less than a tenth of an inch, except higher amounts possible in thunderstorms. \"/>\n",
      "    </p>\n",
      "    <p class=\"temp temp-low\">\n",
      "     Low: 48 °F\n",
      "    </p>\n",
      "    <p class=\"short-desc\">\n",
      "     Showers then\n",
      "     <br/>\n",
      "     Rain Likely\n",
      "    </p>\n",
      "   </div>\n",
      "  </li>\n",
      "  <li class=\"forecast-tombstone\">\n",
      "   <div class=\"tombstone-container\">\n",
      "    <p class=\"period-name\">\n",
      "     Friday\n",
      "    </p>\n",
      "    <p>\n",
      "     <img alt=\"Friday: A 40 percent chance of rain, mainly before 10am.  Mostly sunny, with a high near 61. West southwest wind 9 to 11 mph, with gusts as high as 22 mph. \" class=\"forecast-icon\" src=\"newimages/medium/ra40.png\" title=\"Friday: A 40 percent chance of rain, mainly before 10am.  Mostly sunny, with a high near 61. West southwest wind 9 to 11 mph, with gusts as high as 22 mph. \"/>\n",
      "    </p>\n",
      "    <p class=\"temp temp-high\">\n",
      "     High: 61 °F\n",
      "    </p>\n",
      "    <p class=\"short-desc\">\n",
      "     Chance Rain\n",
      "    </p>\n",
      "   </div>\n",
      "  </li>\n",
      "  <li class=\"forecast-tombstone\">\n",
      "   <div class=\"tombstone-container\">\n",
      "    <p class=\"period-name\">\n",
      "     Friday Night\n",
      "    </p>\n",
      "    <p>\n",
      "     <img alt=\"Friday Night: Mostly clear, with a low around 40. South southwest wind around 5 mph becoming calm  in the evening. \" class=\"forecast-icon\" src=\"newimages/medium/nfew.png\" title=\"Friday Night: Mostly clear, with a low around 40. South southwest wind around 5 mph becoming calm  in the evening. \"/>\n",
      "    </p>\n",
      "    <p class=\"temp temp-low\">\n",
      "     Low: 40 °F\n",
      "    </p>\n",
      "    <p class=\"short-desc\">\n",
      "     Mostly Clear\n",
      "    </p>\n",
      "   </div>\n",
      "  </li>\n",
      "  <li class=\"forecast-tombstone\">\n",
      "   <div class=\"tombstone-container\">\n",
      "    <p class=\"period-name\">\n",
      "     Saturday\n",
      "    </p>\n",
      "    <p>\n",
      "     <img alt=\"Saturday: Partly sunny, with a high near 59.\" class=\"forecast-icon\" src=\"newimages/medium/bkn.png\" title=\"Saturday: Partly sunny, with a high near 59.\"/>\n",
      "    </p>\n",
      "    <p class=\"temp temp-high\">\n",
      "     High: 59 °F\n",
      "    </p>\n",
      "    <p class=\"short-desc\">\n",
      "     Partly Sunny\n",
      "    </p>\n",
      "   </div>\n",
      "  </li>\n",
      "  <li class=\"forecast-tombstone\">\n",
      "   <div class=\"tombstone-container\">\n",
      "    <p class=\"period-name\">\n",
      "     Saturday Night\n",
      "    </p>\n",
      "    <p>\n",
      "     <img alt=\"Saturday Night: Mostly cloudy, with a low around 42.\" class=\"forecast-icon\" src=\"newimages/medium/nbkn.png\" title=\"Saturday Night: Mostly cloudy, with a low around 42.\"/>\n",
      "    </p>\n",
      "    <p class=\"temp temp-low\">\n",
      "     Low: 42 °F\n",
      "    </p>\n",
      "    <p class=\"short-desc\">\n",
      "     Mostly Cloudy\n",
      "    </p>\n",
      "   </div>\n",
      "  </li>\n",
      "  <li class=\"forecast-tombstone\">\n",
      "   <div class=\"tombstone-container\">\n",
      "    <p class=\"period-name\">\n",
      "     Sunday\n",
      "    </p>\n",
      "    <p>\n",
      "     <img alt=\"Sunday: A slight chance of rain.  Mostly cloudy, with a high near 59.\" class=\"forecast-icon\" src=\"newimages/medium/ra.png\" title=\"Sunday: A slight chance of rain.  Mostly cloudy, with a high near 59.\"/>\n",
      "    </p>\n",
      "    <p class=\"temp temp-high\">\n",
      "     High: 59 °F\n",
      "    </p>\n",
      "    <p class=\"short-desc\">\n",
      "     Slight Chance\n",
      "     <br/>\n",
      "     Rain\n",
      "    </p>\n",
      "   </div>\n",
      "  </li>\n",
      " </ul>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 1: Identify the Target URL\n",
    "# ----------------------------------------------------------------------------\n",
    "# This URL corresponds to the National Weather Service’s 7-day forecast\n",
    "# for a specific latitude/longitude near Davis, CA.\n",
    "url = \"https://forecast.weather.gov/MapClick.php?lat=38.54669&lon=-121.74457#.Y9fY5vv565t\"\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 2: Fetch the Page Content\n",
    "# ----------------------------------------------------------------------------\n",
    "try:\n",
    "    # 'requests.get(url)' sends an HTTP GET request to the specified URL.\n",
    "    # The server's response is stored in the 'response' variable.\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # 'raise_for_status()' will raise a 'requests.exceptions.HTTPError' if\n",
    "    # the server returned an unsuccessful status code (e.g., 404, 500).\n",
    "    response.raise_for_status()\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    # If *any* Request-related error occurs (connection error, timeout, etc.),\n",
    "    # print the error and exit the script gracefully.\n",
    "    print(f\"Error fetching {url}:\\n{e}\")\n",
    "    raise SystemExit\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3: Parse HTML with BeautifulSoup\n",
    "# ----------------------------------------------------------------------------\n",
    "# 'response.text' gives us the HTML content of the response.\n",
    "# BeautifulSoup constructs a \"soup\" object from that text for easy parsing.\n",
    "html_soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 4: Identify and Validate the \"Seven-Day Forecast\" Section\n",
    "# ----------------------------------------------------------------------------\n",
    "# The page structure (from NWS) typically includes a <div> with id=\"seven-day-forecast-container\".\n",
    "# We find it using 'html_soup.find(id=\"...\")'.\n",
    "seven_day = html_soup.find(id=\"seven-day-forecast-container\")\n",
    "\n",
    "# If 'find' returned None, it means it couldn’t locate that <div> — likely\n",
    "# because the site’s structure changed or the page didn’t load fully.\n",
    "if not seven_day:\n",
    "    raise ValueError(\n",
    "        \"Could not find the element with id='seven-day-forecast-container'. \"\n",
    "        \"The site structure may have changed.\"\n",
    "    )\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Optional: Debugging / Inspect the snippet\n",
    "# ----------------------------------------------------------------------------\n",
    "# If you want to see exactly what we got in 'seven_day', you can uncomment the line:\n",
    "print(seven_day.prettify())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb98acea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOW: Multiple hazards in effect',\n",
       " 'Tonight',\n",
       " 'Thursday',\n",
       " 'Thursday Night',\n",
       " 'Friday',\n",
       " 'Friday Night',\n",
       " 'Saturday',\n",
       " 'Saturday Night',\n",
       " 'Sunday']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .find_all() returns a list of matching <p> elements.\n",
    "period_names = seven_day.find_all(\"p\", class_=\"period-name\")\n",
    "\n",
    "# We then iterate over each found <p> element and use .get_text(strip=True)\n",
    "# to extract only the text content, trimming whitespace.\n",
    "period = [name.get_text(strip=True) for name in period_names]\n",
    "period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0698b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "<div id=\"seven-day-forecast-container\">\n",
    "  <ul id=\"seven-day-forecast-list\">\n",
    "    <li class=\"forecast-tombstone\">\n",
    "      <div class=\"tombstone-container\">\n",
    "        <p class=\"period-name\">Tonight</p>\n",
    "        <p>\n",
    "          <img class=\"forecast-icon\"\n",
    "               src=\"newimages/medium/nshra100.png\"\n",
    "               title=\"Tonight: Rain likely. Low around 46. Chance of precipitation is 70%.\" />\n",
    "        </p>\n",
    "        <p class=\"short-desc\">Rain Likely</p>\n",
    "        <p class=\"temp temp-low\">Low: 46 °F</p>\n",
    "      </div>\n",
    "    </li>\n",
    "\n",
    "    <li class=\"forecast-tombstone\">\n",
    "      <div class=\"tombstone-container\">\n",
    "        <p class=\"period-name\">Thursday</p>\n",
    "        <p>\n",
    "          <img class=\"forecast-icon\"\n",
    "               src=\"newimages/medium/shra80.png\"\n",
    "               title=\"Thursday: Showers. High near 60. Chance of precipitation is 80%.\" />\n",
    "        </p>\n",
    "        <p class=\"short-desc\">Showers</p>\n",
    "        <p class=\"temp temp-high\">High: 60 °F</p>\n",
    "      </div>\n",
    "    </li>\n",
    "\n",
    "    <li class=\"forecast-tombstone\">\n",
    "      <div class=\"tombstone-container\">\n",
    "        <p class=\"period-name\">Thursday Night</p>\n",
    "        <p>\n",
    "          <img class=\"forecast-icon\"\n",
    "               src=\"DualImage.php?i=nshra&amp;j=nshra&amp;ip=100&amp;jp=70\"\n",
    "               title=\"Thursday Night: Showers likely. Low around 48. Chance of precipitation is 100%.\" />\n",
    "        </p>\n",
    "        <p class=\"short-desc\">Showers Likely</p>\n",
    "        <p class=\"temp temp-low\">Low: 48 °F</p>\n",
    "      </div>\n",
    "    </li>\n",
    "  </ul>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
