{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15098a09",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# STA 141B Data & Web Technologies for Data Analysis\n",
    "\n",
    "### Lecture 10, 2/11/25, Scraping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d147956",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    " - Midterm grades are online"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94368e94",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Last week's topics\n",
    "\n",
    " - Web APIs\n",
    "     - documented APIs\n",
    "     - undocumented APIs\n",
    "     - devtools\n",
    "     - `requests` package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578cb966",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Today's topics\n",
    "\n",
    " - Scraping Tables with `pandas`\n",
    " - HTML\n",
    " - XML\n",
    " - Parser\n",
    " - Extracting Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9786cb",
   "metadata": {},
   "source": [
    "### Ressources\n",
    "\n",
    "* [`requests` documentation](http://docs.python-requests.org/en/master/)\n",
    "* [`requests-html` documentation](https://html.python-requests.org/)\n",
    "* [W3 Schools](https://www.w3schools.com/html/default.asp)\n",
    "* [MDN HTML Reference](https://developer.mozilla.org/en-US/docs/Web/HTML/Element)\n",
    "* [XPath Diner](http://www.topswagcode.com/xpath/) - an interactive XPath tutorial\n",
    "* [CSS Diner](https://flukeout.github.io/) - an interactive CSS Selector tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3638175",
   "metadata": {},
   "source": [
    "### Scraping Tables with `pandas`\n",
    "\n",
    "For data in a `table` element, we can use __Pandas__ instead of writing a scraper. \n",
    "\n",
    "Wikipedia provides lots of useful information in tables. Let's get the Wikipedia list of [US cities by area][wiki].\n",
    "\n",
    "[wiki]: https://en.wikipedia.org/wiki/List_of_United_States_cities_by_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a91e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b689f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabs = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dc400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ad88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64edc88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deddf014",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = tabs[1]\n",
    "tbl.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba33fb",
   "metadata": {},
   "source": [
    "To process this information, unusable items have to be removed. We are going to do that with `regex`. We will learn more about `regex` later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6917a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import sub \n",
    "def remove(string):\n",
    "    '''\n",
    "    Removes everything inside [], a whitespace before that and *'s.\n",
    "    '''\n",
    "    if isinstance(string, str):\n",
    "        string = sub(r'\\s*\\[.*\\]\\**', '', string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6a8771",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl['City'].iloc[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a84c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove(tbl['City'].iloc[4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a3c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove(1706.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cb530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.columns = [remove(i) for i in tbl.columns] # remove from table columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dbd879",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = tbl.applymap(remove) #remove from all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee66cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd78eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad1aed1",
   "metadata": {},
   "source": [
    "### HTML\n",
    "\n",
    "Web pages are written in _hypertext markup language_ (HTML). HTML files (`.htm` or `.html`) are plain text, just like JSON, Python scripts, and R scripts.\n",
    "\n",
    "In HTML, we use _tags_ to create _elements_ of a web page. Elements add formatting and structure to the page.\n",
    "\n",
    "* Tags usually come in pairs: an opening tag and a closing tag.\n",
    "* Tags are written `<NAME>` for opening tags, `</NAME>` for closing tags, and `<NAME />` for singleton tags.\n",
    "* Opening and singleton tags can have _attributes_ that contain additional information. Attributes are written `ATTRIBUTE=VALUE` after the tag name. \n",
    "\n",
    "See [here](https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/HTML_basics) for a more detailed explanation, and [here](https://developer.mozilla.org/en-US/docs/Web/HTML/Element) for a list of valid HTML elements.\n",
    "\n",
    "#### Example\n",
    "\n",
    "[wiki]: https://en.wikipedia.org/wiki/List_of_United_States_cities_by_area\n",
    "\n",
    "From now on, we will use an artificial an example:\n",
    "\n",
    "```html\n",
    "<p>This page is famous and this <b>word</b> is emphasized.</p>\n",
    "```\n",
    "\n",
    "```html\n",
    "<p>This <a href=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\">page</a> is famous and this <strong>word</strong> is emphasized.</p>\n",
    "```\n",
    "\n",
    "```html\n",
    "<li>1. Something</li>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6092a23",
   "metadata": {},
   "source": [
    "<p>This page is famous and this <b>word</b> is emphasized.</p>\n",
    "<p>This <a href=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\">page</a> is famous and this <strong>word</strong> is emphasized.</p>\n",
    "<li>1. Something</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdbdbed",
   "metadata": {},
   "source": [
    "The `p` tag marks a paragraph, the `a` tag marks a link (an _anchor_), the `strong` tag marks emphasized text,\n",
    "and `li` tag marks a list.\n",
    "\n",
    "Here's a string that contains HTML for a simple, complete website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaa9d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "    <title>This is the Title!</title>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "    <p>This is a paragraph!</p>\n",
    "    <p id=\"best-paragraph\">This is another paragraph! &#127790; and another anchor <a href=\"https://pudding.cool\"> asdf</a> </p>\n",
    "    <p>Visit <a href=\"https://pudding.cool\"> The Pudding</a>.</p>\n",
    "    <span>This is a span, it comes with an taco &#127790;</span>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c32524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc520e8e",
   "metadata": {},
   "source": [
    "<html>\n",
    "<head>\n",
    "    <title>This is the Title!</title>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "    <p>This is a paragraph!</p>\n",
    "    <p id=\"best-paragraph\">This is another paragraph! &#127790;</p>\n",
    "    <p>Visit <a href=\"https://pudding.cool\">The Pudding</a>.</p>\n",
    "    <span>This is a span, it comes with an taco &#127790;</span>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2c0076",
   "metadata": {},
   "source": [
    "The `<span>` tag is an inline container used to mark up a part of a text, or a part of a document.\n",
    "    \n",
    "For example, you can write the code\n",
    "```\n",
    "<p>My hat is <span style=\"color:blue\">blue</span>.</p>    \n",
    "```  \n",
    "    \n",
    "<p>My hat is <span style=\"color:blue\">blue</span>.</p>     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d11b63",
   "metadata": {},
   "source": [
    "### XML\n",
    "\n",
    "_Extensible markup language_ (XML) also uses tags to create elements. We say XML is _extensible_ because you can create your own XML elements (unlike HTML). People typically use XML to describe structure and meaning of data, rather than for formatting.\n",
    "\n",
    "We'll use the same process to extract data from both HTML and XML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9e1074",
   "metadata": {},
   "source": [
    "### Parser\n",
    "\n",
    "A _parser_ converts formatted data into familiar data structures. We've used __requests__' built-in JSON parser, but the package doesn't have a built-in HTML/XML parser. Fortunately, there are many other Python packages for parsing HTML/XML and web scraping.\n",
    "\n",
    "HTML/XML Parsers:\n",
    "* [lxml](https://lxml.de/)\n",
    "* [html5lib](https://github.com/html5lib/html5lib-python)\n",
    "* [beautifulsoup](https://www.crummy.com/software/BeautifulSoup/)\n",
    "* [requests-html](https://docs.python-requests.org/projects/requests-html/en/latest/)\n",
    "\n",
    "Scraper Frameworks (_convenient after learning the basics with parsers_):\n",
    "* [scrapy](https://scrapy.org/)\n",
    "* [newspaper3k](https://github.com/codelucas/newspaper)\n",
    "\n",
    "Even more [here](https://github.com/lorien/awesome-web-scraping/blob/master/python.md#web-scraping-frameworks).\n",
    "\n",
    "We'll use __lxml__ here (check the [doc](https://lxml.de/apidoc/index.html)), but you're welcome to use other packages on assignments and the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dfe76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.html as lx\n",
    "\n",
    "html = lx.fromstring(page)\n",
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f03b8e",
   "metadata": {},
   "source": [
    "<html>\n",
    "<head>\n",
    "    <title>This is the Title!</title>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "    <p>This is a paragraph!</p>\n",
    "    <p id=\"best-paragraph\">This is another paragraph! &#127790; and another anchor <a href=\"https://pudding.cool\"> asdf</a> </p>\n",
    "    <p>Visit <a href=\"https://pudding.cool\"> The Pudding</a>.</p>\n",
    "    <span>This is a span, it comes with an taco &#127790;</span>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c221385f",
   "metadata": {},
   "source": [
    "#### Finding Elements\n",
    "\n",
    "Elements are nested, so an HTML document is like a tree:\n",
    "```\n",
    "html\n",
    "├── head\n",
    "│   └── title\n",
    "└── body\n",
    "    ├── p\n",
    "    ├── p\n",
    "    ├── p\n",
    "    │   └── a\n",
    "    └── span\n",
    "```\n",
    "This is similar to the file system on your computer. The key difference is that elements at the same level can have the same tag name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2848c3",
   "metadata": {},
   "source": [
    "#### XPath\n",
    "\n",
    "The _XML Path Language_ (XPath) lets us write paths to elements. XPath paths look a lot like file paths. XPath is not Python-specific!\n",
    "\n",
    "The `.xpath()` method gets all elements at an XPath path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a58390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.xpath(\"/html/head/title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb42c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.xpath(\"//p/a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f03110",
   "metadata": {},
   "source": [
    "Since there may be more than one element, the method always returns a list.\n",
    "\n",
    "Absolute paths are not robust for scraping. An update to a web page that adds a single tag can break a scraper that uses absolute paths. In XPath, `//` means \"anywhere below\". We'll use `//` often because it's more robust:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fd81c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.xpath(\"//a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e989eb7",
   "metadata": {},
   "source": [
    "What if we just elements want that satisfy a certain condition? In XPath, `[ ]` filters out elements that don't match a condition. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9aac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.xpath(\"//p[@id = 'best-paragraph']/a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e558e11",
   "metadata": {},
   "source": [
    "[XPath Diner](http://www.topswagcode.com/xpath/) is an interactive tutorial that teaches most of the XPath syntax. It takes about 20-60 minutes. Work through it to become an XPath ninja! \n",
    "\n",
    "You can copy the absolute path of a tag from the developer tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'/html/body/div[2]/div/div[3]/main/div[3]/div[4]/div[1]/div[5]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d05b35b",
   "metadata": {},
   "source": [
    "#### CSS Selectors\n",
    "\n",
    "_Cascading Style Sheets_ (CSS) is another language for formatting elements in an HTML document. CSS provides another way to select elements, called _CSS selectors_.\n",
    "\n",
    "CSS selectors are more concise but less flexible than XPath paths. The `.cssselect()` method gets all elements at a CSS selector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7825d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.cssselect(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadfc8ee",
   "metadata": {},
   "source": [
    "Check out the [CSS Diner](https://flukeout.github.io/)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c71722",
   "metadata": {},
   "source": [
    "### Extracting Text and Attributes\n",
    "\n",
    "There are two ways to get text from an element:\n",
    "\n",
    "* `.text` gives text inside the element, but not its children\n",
    "* `.text_content()` gives text inside the element and its children, with all tags removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd22d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a97613",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = html.xpath(\"//a\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87901bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f69714",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.text_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76cd016",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00537b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.text_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb1d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d50518",
   "metadata": {},
   "source": [
    "We can get values from attributes on an element with `.attrib`, which is a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b58916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.attrib[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7ce541",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.attrib[\"href\"] for x in html.xpath(\"//a\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce991f1",
   "metadata": {},
   "source": [
    "### Writing Scrapers\n",
    "\n",
    "Lets scrape the wiki table ourselves. Attention: We are using request, so pay attention to the file that is being returned. Check on devtools the html element for `<thead>` and see what is returned in the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec78e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "result = requests.get(url = 'https://en.wikipedia.org/wiki/List_of_United_States_cities_by_area')\n",
    "html = lx.fromstring(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8febeb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = html.xpath('//table')\n",
    "table = tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd878dd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table.text_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc608c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.xpath('//thead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c820d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.xpath('//table[2]/tbody')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d577f7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_rows(html): \n",
    "    rows = html.xpath('//table[2]/tbody/tr')\n",
    "    cells = []\n",
    "    for row in rows: \n",
    "        # ./td|th means we start at the node (not searching the whole doc again), and choose td OR th children\n",
    "        cells.append([cell.text_content() for cell in row.xpath('./td|th')]) # no text, as some cells are in <b>\n",
    "    return cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23969135",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_rows(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24deb79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(retrieve_rows(html))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee79dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.iloc[0]\n",
    "df = df.drop(index = range(2))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca23bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import sub \n",
    "def remove(string):\n",
    "    '''\n",
    "    Removes everything inside [], a whitespace before that and *'s.\n",
    "    '''\n",
    "    if isinstance(string, str):\n",
    "        string = sub(r'\\s*\\[.*\\]\\**|\\n|,', '', string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d41f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [remove(i) for i in df.columns] # remove from table columns\n",
    "df = df.applymap(remove) #remove from all rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f312dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc238d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns[2:]: #only those cols with vals\n",
    "    df[col] = df[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e01abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7d6809",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3a64d8",
   "metadata": {},
   "source": [
    "### Summary \n",
    "\n",
    "- HTML pages are set up like a filesystem\n",
    "- use `lxml` to parse them in Python\n",
    "- navigate though HTML via xpath or css"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
